<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tutorial CodeT5 - IA para Gera√ß√£o de C√≥digo</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 20px; }
        .container { max-width: 900px; margin: 0 auto; background: white; border-radius: 20px; padding: 40px; box-shadow: 0 20px 60px rgba(0,0,0,0.3); }
        h1 { color: #667eea; font-size: 2.5em; margin-bottom: 10px; }
        .subtitle { color: #666; font-size: 1.2em; margin-bottom: 30px; }
        .step { background: #f8f9fa; padding: 25px; border-radius: 10px; margin: 20px 0; border-left: 5px solid #667eea; }
        .step h2 { color: #333; margin-bottom: 15px; font-size: 1.5em; }
        .step p { color: #555; line-height: 1.8; margin-bottom: 10px; }
        .code-block { background: #2d2d2d; color: #f8f8f2; padding: 20px; border-radius: 8px; margin: 15px 0; overflow-x: auto; font-family: 'Courier New', monospace; font-size: 14px; }
        .info-box { background: #e3f2fd; border-left: 4px solid #2196F3; padding: 15px; margin: 15px 0; border-radius: 5px; }
        .warning-box { background: #fff3cd; border-left: 4px solid #ffc107; padding: 15px; margin: 15px 0; border-radius: 5px; }
        .success-box { background: #d4edda; border-left: 4px solid #28a745; padding: 15px; margin: 15px 0; border-radius: 5px; }
        ul { margin-left: 20px; color: #555; line-height: 1.8; }
        @media print { body { background: white; padding: 0; } .container { box-shadow: none; } }
    </style>
</head>
<body>
    <div class="container">
        <h1>üìö Tutorial CodeT5</h1>
        <p class="subtitle">IA para Gera√ß√£o e Compreens√£o de C√≥digo em M√∫ltiplas Linguagens</p>

        <div class="step">
            <h2>1. O que √© CodeT5?</h2>
            <p>CodeT5 √© um modelo de IA desenvolvido pela Salesforce baseado na arquitetura T5 (Text-to-Text Transfer Transformer), especialmente treinado para tarefas de programa√ß√£o. Ele pode gerar c√≥digo, traduzir entre linguagens, resumir c√≥digo e realizar refatora√ß√£o.</p>
            <div class="info-box">
                <strong>Principais Capacidades:</strong>
                <ul>
                    <li>Gera√ß√£o de c√≥digo a partir de descri√ß√µes em linguagem natural</li>
                    <li>Tradu√ß√£o entre diferentes linguagens de programa√ß√£o</li>
                    <li>Resumo e documenta√ß√£o autom√°tica de c√≥digo</li>
                    <li>Refatora√ß√£o e otimiza√ß√£o de c√≥digo</li>
                    <li>Detec√ß√£o de bugs e sugest√µes de corre√ß√£o</li>
                </ul>
            </div>
        </div>

        <div class="step">
            <h2>2. Instala√ß√£o e Configura√ß√£o</h2>
            <p>Para usar o CodeT5, voc√™ precisa instalar as bibliotecas necess√°rias:</p>
            <div class="code-block">pip install transformers torch
pip install sentencepiece</div>
            <p>C√≥digo b√°sico para carregar o modelo:</p>
            <div class="code-block">from transformers import T5ForConditionalGeneration, RobertaTokenizer

# Carregar modelo e tokenizer
model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base')
tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')

# Fun√ß√£o para gerar c√≥digo
def generate_code(prompt, max_length=200):
    input_ids = tokenizer(prompt, return_tensors="pt").input_ids
    generated_ids = model.generate(input_ids, max_length=max_length)
    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)</div>
        </div>

        <div class="step">
            <h2>3. Gera√ß√£o de C√≥digo</h2>
            <p>Use descri√ß√µes em linguagem natural para gerar c√≥digo:</p>
            <div class="code-block"># Exemplo 1: Gerar fun√ß√£o Python
prompt = "def calculate_fibonacci(n):"
result = generate_code(prompt)
print(result)

# Exemplo 2: Criar classe
prompt = "class BankAccount:"
result = generate_code(prompt)
print(result)

# Exemplo 3: Algoritmo espec√≠fico
prompt = "Write a function to sort an array using quicksort"
result = generate_code(prompt)
print(result)</div>
            <div class="success-box">
                <strong>Dica:</strong> Seja espec√≠fico na descri√ß√£o. Quanto mais detalhes voc√™ fornecer, melhor ser√° o c√≥digo gerado.
            </div>
        </div>

        <div class="step">
            <h2>4. Tradu√ß√£o Entre Linguagens</h2>
            <p>CodeT5 pode traduzir c√≥digo de uma linguagem para outra:</p>
            <div class="code-block"># Traduzir de Python para Java
python_code = """
def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n-1)
"""

prompt = f"Translate Python to Java: {python_code}"
java_code = generate_code(prompt, max_length=300)
print(java_code)

# Traduzir de JavaScript para Python
js_code = """
function sumArray(arr) {
    return arr.reduce((sum, num) => sum + num, 0);
}
"""

prompt = f"Translate JavaScript to Python: {js_code}"
python_code = generate_code(prompt, max_length=300)
print(python_code)</div>
        </div>

        <div class="step">
            <h2>5. Resumo e Documenta√ß√£o</h2>
            <p>Gere documenta√ß√£o autom√°tica para seu c√≥digo:</p>
            <div class="code-block"># Gerar docstring
code = """
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1
"""

prompt = f"Generate documentation for: {code}"
documentation = generate_code(prompt, max_length=200)
print(documentation)

# Resumir c√≥digo complexo
prompt = f"Summarize this code: {code}"
summary = generate_code(prompt, max_length=100)
print(summary)</div>
        </div>

        <div class="step">
            <h2>6. Refatora√ß√£o de C√≥digo</h2>
            <p>Melhore a qualidade do seu c√≥digo:</p>
            <div class="code-block"># C√≥digo n√£o otimizado
bad_code = """
def find_max(numbers):
    max_num = numbers[0]
    for i in range(len(numbers)):
        if numbers[i] > max_num:
            max_num = numbers[i]
    return max_num
"""

prompt = f"Refactor and optimize: {bad_code}"
optimized_code = generate_code(prompt, max_length=200)
print(optimized_code)

# Melhorar legibilidade
messy_code = """
def f(x,y,z):return x+y*z if z>0 else x-y
"""

prompt = f"Improve code readability: {messy_code}"
clean_code = generate_code(prompt, max_length=150)
print(clean_code)</div>
        </div>

        <div class="step">
            <h2>7. Detec√ß√£o de Bugs</h2>
            <p>Identifique e corrija erros no c√≥digo:</p>
            <div class="code-block"># C√≥digo com bug
buggy_code = """
def divide_numbers(a, b):
    return a / b
"""

prompt = f"Find and fix bugs in: {buggy_code}"
fixed_code = generate_code(prompt, max_length=200)
print(fixed_code)

# An√°lise de seguran√ßa
insecure_code = """
def execute_query(user_input):
    query = "SELECT * FROM users WHERE name = '" + user_input + "'"
    return execute(query)
"""

prompt = f"Identify security issues: {insecure_code}"
analysis = generate_code(prompt, max_length=250)
print(analysis)</div>
        </div>

        <div class="step">
            <h2>8. Uso Avan√ßado com Fine-tuning</h2>
            <p>Personalize o modelo para suas necessidades espec√≠ficas:</p>
            <div class="code-block">from transformers import Trainer, TrainingArguments

# Preparar dados de treinamento
train_dataset = [
    {"input": "Create a REST API endpoint", "output": "code here"},
    # Mais exemplos...
]

# Configurar treinamento
training_args = TrainingArguments(
    output_dir="./codet5-finetuned",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    save_steps=1000,
    save_total_limit=2,
)

# Treinar modelo
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
)

trainer.train()</div>
            <div class="warning-box">
                <strong>Aten√ß√£o:</strong> Fine-tuning requer recursos computacionais significativos (GPU recomendada) e um dataset de qualidade.
            </div>
        </div>

        <div class="step">
            <h2>9. Integra√ß√£o com IDEs</h2>
            <p>Crie uma extens√£o simples para VS Code:</p>
            <div class="code-block"># server.py - Backend Flask
from flask import Flask, request, jsonify
from transformers import T5ForConditionalGeneration, RobertaTokenizer

app = Flask(__name__)
model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base')
tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')

@app.route('/generate', methods=['POST'])
def generate():
    prompt = request.json['prompt']
    input_ids = tokenizer(prompt, return_tensors="pt").input_ids
    generated_ids = model.generate(input_ids, max_length=200)
    code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)
    return jsonify({'code': code})

if __name__ == '__main__':
    app.run(port=5000)</div>
        </div>

        <div class="step">
            <h2>10. Melhores Pr√°ticas</h2>
            <div class="info-box">
                <strong>Dicas para Resultados √ìtimos:</strong>
                <ul>
                    <li><strong>Prompts Claros:</strong> Seja espec√≠fico sobre o que deseja</li>
                    <li><strong>Contexto:</strong> Forne√ßa informa√ß√µes sobre o ambiente e requisitos</li>
                    <li><strong>Itera√ß√£o:</strong> Refine os resultados com prompts adicionais</li>
                    <li><strong>Valida√ß√£o:</strong> Sempre revise e teste o c√≥digo gerado</li>
                    <li><strong>Seguran√ßa:</strong> Verifique vulnerabilidades no c√≥digo gerado</li>
                    <li><strong>Performance:</strong> Use cache para prompts frequentes</li>
                </ul>
            </div>
        </div>

        <div class="success-box">
            <strong>‚úÖ Recursos Adicionais:</strong>
            <ul>
                <li>Documenta√ß√£o oficial: <a href="https://huggingface.co/Salesforce/codet5-base" target="_blank">HuggingFace CodeT5</a></li>
                <li>Paper original: "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation"</li>
                <li>GitHub: Exemplos e notebooks pr√°ticos</li>
            </ul>
        </div>
    </div>
</body>
</html>